ChatGPT专家交流0217    1、ChatGPT出来之后，对我们国内相关产业的影响？

国内相关的厂商，阿里、百度未来一段时间落地情况？

    A：关于从国家层面，GPT这个产品推出以后，网信办已经发出了一些政策相关的东西。

从国家层面的角度来说，短期内我们很难看到ChatGPT这些产品直接跟国内的应用，或者做比较深度的结合，因为这块不管是基于信息安全，还是国内的一些产业保护的角度来说，国内可能都得需要有这样一个窗口期，得需要有逐步缓冲的时间。

所以，国家后续会出台相关的政策，给国内的玩家们提供追赶的时机。

    从我们之前对百度文心类似产品的使用体验来看，内容的质量上百度文心和ChatGPT差距不是特别大，只是在内容的多样性上有差距。

咱们国内研究相关的大模型的，目前主要靠工程人员和研发人员，大概几百号人或者上千号人这么研发，在这个过程中没有引入像OpenAI这种用户反馈机制，没有大量的用户在技术模型的迭代过程中参与进来。

所以在内容的多样性上会有所欠缺。

    第三，可能跟目前实际没有放开政策有关系，就是比如像ChatGPT响应能力，一个Q过去，A回来大概是1-3秒，响应能力比较快。

目前百度文心这边我们能够体验到的，大概短的在20秒左右，长的甚至在80秒以上。

当然这个不是技术瓶颈问题，需要在模型研发完成以后，我需要在服务器做部署，部署完之后支持数以百万计，甚至数以千万计高并发访问的需求，这块属于常态的部分。

未来3-6个月左右的时间，像百度文心、阿里推出类似于ChatGPT的产品应该可以达到目前ChatGPT60%-70%左右的水平。

    2、ChatGPT出来之后，一开始在美国程序圈特别火，比如说从应用层面，或者算力层面有什么样对行业的影响？

百度或者其他有没有正在加大投入的？

    A：先说一下整个参与的玩家，只说国内。

像百度已经宣布了，阿里达摩院也宣布了会投入3-5个亿的基金做这块。

当然还有我们想不到的，比如说美团前合伙人也宣布下海做这件事情。

当然可能在其他的领域，包括您提到的字节，也对之前一些GPT2.0、3.0，可能以开源的模型作为基础，也做了一些相应的优化，也跟这些客户推相关的解决方案。

    像字节也做了一些优化。

主要是训练过程，在云服务架构上，通用的算力部署，大概会有1.5-2.5倍的效率提升。

可能跟我们接触的部门有关系，它自己没有单纯的训练大模型，更多的想把服务包给愿意做大模型的公司。

    这个模型训练的成本主要有三个方面，单纯从基础算力投入这块大概是384块到3000块左右的A100的投入，基本上可以满足要求。

这块的费用大概400-1000万美金，最多到3000万美金的规模，所以对于很多巨头、独角兽甚至一些初创团队，其实都有能力做这个投入。

而且它的算法的基础都是基于预训练这样一种机制。

所以参与的玩家会比我们想象的要多。

关于技术跟行业结合的影响，短期内主要是有两个大的方向。

一个方向就是不管是谷歌也好，还是微软也好，肯定会跟搜索引擎做结合。

这块主要是用来提升搜索引擎的信息获取的效率。

第二个大的方向，对于微软来说更加有优势，就是把类似于ChatGPT的这种技术跟办公软件做结合。

因为跟办公软件做结合有一个好处，它可以提高日常生活工作的效率。

比如说处理表格，或者写一写小作文，类似这种可以提高效率。

而且可以很好的在工具软件的定位上，把一些资讯的敏感性过滤掉。

如果只是单纯的跟搜索引擎结合的话，这里面可能会有一些政策、政治、意识形态，类似这方面的影响。

而且从内容的提供信息给终端用户使用的角度来说，AIGC这种方式也存在一个被大家忽略掉的风险，以百度、谷歌来举例子，比如说传统的搜索引擎的提供商都是通过快照这种方式把信息抓取过来，实际上用户看到的是一个个的链接。

用户点进去这些链接查看自己想要的信息，出了问题承担责任的话，其实是可以通过这个链接找到一个最终的责任方。

即使像之前百度跟莆田系的关系一样，尽管可能口碑不好，但是我可以找到莆田系的医院承担最终的责任。

但是目前以类似ChatGPT的技术，相当于对这些信息做了二次加工，这个责任的主体其实已经在这个过程中发生了变化。

所以这时候其实如果大家没有意识到这一点的话，可能承担责任的话，谁提供这个信息，谁提供这个产品，就变成了最终的责任方。

所以在具体的内容呈现上，可能还需要做一些优化。

    3、投入成本方面，您指的是比如说需要买算力芯片、服务器芯片的成本，还是算法工程师上面的投入成本？

    A：要做大模型的话，算法成本一共是包括三部分。

    第一，刚才已经提到的这部分，基础的算力投入，这块大概是三四百万美金到一千万美金左右的规模，无非是我投入的少，训练的时间长一些，比如说170天，200天，大概这样的。

如果投入的多一些，像英伟达也在合作做大模型，五千亿的参数，我投入了3072块A100做训练，这块效率可以缩短到20-30天。

这个成本在整个大模型训练过程中最少的。

真正的大头在数据采集、模型的技术迭代和优化过程中。

这一块需要堆集大量的研发人员、工程师、科学家做这方面的工作。

比如说数据采集，我们要抓取整个新浪、网易、搜狐、知乎这些网站的数据，因为这些网站都有反爬虫的策略，所以需要堆集大量的人员去写破解反抓取策略的策略，这块会耗费大量的人力和工程师的时间。

    第二，引入用户反馈机制，这时候不仅仅是研发人员了，有大量的标注人员，有大量的用户参与，这块耗费的一个是时间长，另外一个是成本高。

对于OpenAI来说，每年在这块的投入在1亿到1.5亿左右美金的规模，这是比较大的地方。

因为数据采集和处理的时间会远大于单纯训练的时间。

第三，模型正式上线了，运维和部署。

像ChatGPT一样，上线以后很快获得日活一亿左右的庞大的用户群体，这个过程中我要处理数以十万计，甚至数以百万计的请求。

过程中需要堆集大量的服务器，需要做分布式部署，需要做负载均衡，甚至搭载网络安全策略，防止黑客攻击。

这个过程中还会产生大量的比如说电力的消耗，这块每年的成本至少在五千万美金以上。

所以主要由这么三大部分构成的。

    4、您说到的这几块，是不是也要分训练相关的成本，以及运营过程中的三块的成本。

这块会有什么差异吗？

A：比如说前两部分，我们都可以归纳为是训练的成本，第三部分可以归纳为服务正式部署上线之后运营方面的成本。

    5、像国内的浪潮、海光，他们跟英伟达这块的高算力相关的芯片，或者是服务器能不能支撑上。

如果说英伟达他们的芯片不能卖给中国的话，中国有没有类似的解决方案？

    A：从两个方面说，单纯讲芯片和算力的研发能力这块，我们肯定跟英伟达这些公司是有差距的。

不管您提到的浪潮、华为、寒武纪，哪怕研发出来最顶级的芯片，还是有比较大的差距，这是一块短期内应该还是比较难跟上的。

即使我们在某些技术上有优势，但是最大的问题不是在单纯的技术上，而是在整个生态体系，这块英伟达非常完善。

    我们可以分享一些数据，比如说在全球的超算中心，英伟达大概可以有90%的份额，全球的云服务中心，那边可以有80%的份额，这个其实在短期内很难改变的状态。

再从国内的这些不同类别的厂商，从采购高端显卡的实际情况来看，这种限制肯定会有影响，但是影响可能没有我们想象的这么大，可以说政策是政策，生意是生意。

比如说目前我们国内的四大巨头，像字节、阿里、百度、腾讯这四家公司，在ChatGPT火之前，去年的这些数据每年大概采购A100这种级别的显卡的数量，大致是在2.5万片左右。

像浪潮这些公司，英伟达那边提供了相当于稍微有点阉割的A100，或者H100同级别的显卡和芯片。

基本上没有特别大的影响，至少目前来看。

    6、像百度刚才您说到的一些，您觉得训练出来可能也差不多。

从算法模型来说，因为ChatGPT3.5它是闭源了。

像百度、字节他们未来研发出自己的GPT产品，从过去的3.0开源版本找这些数据，去直接拿它的模型在上面改，还是说需要重新去搭建一个大的模型，这个具体在算法上大概是怎么样去做？

    A：这块目前比如说从字节那边了解到的情况，从阿里那边了解到的情况，基本上都是基于GPT3.0以前，就是开源那些东西拿过来去改，这个相当于是一个基础。

当然GPT3.0的基础也是以预训练模拟训练作为最底层的算法逻辑的。

所以从这个角度讲，你可以理解为大家在通用模型上是一套东西。

尽管不会从0开始的这么一种状态，但是训练的时候OpenAI尽管细节我们没有办法复现，但是至少方向上是明确的。

比如说过程中引入用户反馈机制，用户反馈机制说起来高大上，但是实际上就是堆人，可以简单的这么理解，针对同一个A，我组织成百上千的人去组织或者提问不同的Q，针对同一个Q，组织成百上千的人去回复不同的A。

这个其实就是为了满足内容生成，就是预训练的时候我有大量的多样化丰富的数据，才能够满足AIGC这块基础训练的需要。

其实目前百度文心这块欠缺的可能就是在这一点上，在内容的多样性上，丰富度上有差异。

因为之前我们不要说国内的公司了，包括国外的公司，包括谷歌这边其实也是一样的，它的整个研发过程中，其实普通的用户很少参与，都是堆积大量的工程师、科学家、研究人员做这个工作，在正式公测之前普通用户很少参与。

但是OpenAI经过前几个版本的迭代，在这个过程中发现了普通用户参与的好处，所以才推出了用户反馈机制，大家顺着这个思路做就好了。

细节上可能没有完全复现，但是效果上不会有太大的差距。

    7、在短期没有能够创造收益的情况下，您觉得这些互联网巨头可以持续做这个投入吗？

年化下来费用大概总共是多少？

A：其实对于OpenAI推出ChatGPT来说，在整个的领域，我们现在已经可以看到很多的迹象，不管是前美团的合伙人王慧文总，他自筹资金，搭建团队研发模型，还是说从目前一些招聘渠道，可能对NLP、AIGC相关人才的需求，我们已经可以看到这些迹象，大家都会增加这方面的投入。

之所以会增加这方面的投入，其实是因为OpenAI推出ChatGPT有点像一条鲶鱼，大家如果不跟上这波浪潮，有可能在未来会被甩掉，这是极有可能的。

所以目前大家基于被动防御的策略，我们可以看到不管是谷歌也好，百度也好，阿里也好，这些公司都在宣布往里面投入资金做模型。

所以相对比较短的时间内，因为还有后续的比如说GPT4这些东西不断的推出，所以在未来2-3年的时间里，在这种类似ChatGPT大模型的资本的输出，肯定是一个可以预见的一个地方。

    8、如果放在中长期来看，最终的格局大概率国内就是一两个，两三个大模型最后能跑出来。

现在可能有很多家去投，或者很多家已经有布局，最终要去做这个事情。

您怎么看待这个事，终极来看的话？

    A：如果终极来看的话，个人认为不管国内还是国外，一定会存在多家类似ChatGPT这种大模型。

比如说国外谷歌和微软的关系，包括把苹果也拉进来，甚至特斯拉，我们举个简单的例子。

这些巨头都有可能研发自己的模型，而且他们所处的生态位或者产业略有差异。

比如说像苹果，它有大量的智能终端，把这个能力，或者自己研究大数据的模型跟Siri做结合。

它通过智能设备，比如说打开谷歌的应用，或者打开浏览器去做搜索，会更加的直接，有更高的效率。

再比如说像谷歌和微软，虽然短期内比如说微软借着这个风头，看起来具有领先的优势，它在短期内也的确可以影响到互联网、金融、投资、科技、人工智能相对比较精英的人士，比如说从日常习惯使用谷歌，转移到使用Bing上，但是它无法改变更大的格局，这个格局比如说像谷歌全球的市占率大概在90%还要多一些，Bing大概只有3%-4%之间，因为这些应用嵌入到很多硬件设备当中的，比如说电脑，甚至更多的属于中低端的智能手机设备，所以很难短期内有非常大的市场渗透率。

所以真正决定胜负关键的不是一时的得失，而是参与的玩家所处的生态位，这个生态位决定他可以快速的把这种能力推给他的用户，达到非常高的市占率。

    9、如果我们分技术和应用来看，先说技术这个层面，微软做的这个东西，OpenAI做的这个东西和谷歌现在做的东西，从技术层面会有很大的差异吗？

还是更多是应用场景的差异，大家所拥有的数据资源的差异导致最终的应用效果的差异？

    A：其实单纯从大模型上看，本质上没有特别大的差异，因为现在三大系列的模型，不管GPT，还是Bard，还是XONES（音），都是基于预训练和transform这两种基础，都是谷歌大概在2017年开源的transform那一套基础之上做的。

只不过大家以前有一个创新者困境，而且这些年人工智能除了很久之前的AlphaGo能够让大家感觉到很兴奋以外，在整个过程中一直没有让人感觉特别兴奋的一个点。

所以创新者困境不仅困住了国内和国外巨头的手脚，首先资本上大家不敢过分的往这里投入，谁也不知道我投入5年、10年、8年到底能不能做出来。

    再有一个在团队内部，一个团队负责人工智能的项目，稍微时间长一点，比如说两年，甚至有的短到半年，如果见不到效益，或者没有好的一些东西，这个部门可能就被裁掉了，这个团队也被裁掉了，这跟创新者困境有很大的关系。

现在OpenAI把这个东西推出来以后，因为这么多研究大模型的厂商，之前使用的算法、基础、原理、机制这些基本都是一致的，只不过他们之前可能没有采用像OpenAI采用的用户反馈机制。

当然有一些细节上的调整，这个肯定没有完全的一致。

但是这个用户反馈机制在这里面会非常重要，可能从量变引起质变的效应。

现在大家是创新者困境被破除了，而且OpenAI也给众多的厂商指明了一个方向，你引入这个机制，让更多的用户去参与。

相信这些巨头应该在相对比较短的时间内，会陆续推出自己类似ChatGPT这种产品出来。

    10、ChatGPT其实是基于GPT的应用，从后面GPT这一套，大模型的这套东西来说，应该各家是原理上基本上是类似的，能力上也不会有太大的差异，更多的是涉及的领域，手里的数据资源等等这些方面。

往后看这些东西有没有可能被开源化，类似于像数据湖等等的技术开源化，或者像安卓那样？

    A：这种开源的模型也有，比如说像法国的Big Science推出的blum，可能有很多从谷歌、微软，甚至还有OpenAI这些公司出来的，他们推出一个开源的框架，也是一个类似于ChatGPT的，只是效果怎么样，现在大家没有真正的去做深入的体验。

但是这种开源框架是有的。

考虑到一些实际的情况，特别是跟行业应用做结合，比如说在金融科技领域，在数字政务领域，或者在教育、医疗等等这些实际应用领域的话，单纯的比如说一个模型公司，它能够获取的数据都是基于公开网络上获取的一些数据。

那么像我们刚才说的这些领域的数据，基本上是不对外公开开放的，还是有人需要在这些算法模型基础之上，拿过来做二次的处理，去往垂直领域做相关模型的进一步研发。

    11、如果从技术层面，比如微软和谷歌两个技术层面是类似的，相对他们的不一样更多的体现在他们拥有数据不一样，用户反馈的机制不一样，从而导致使用效果不一样，是可以这么理解吗？

A：其实跟他原有的产品结合上。

比如说微软靠Bing还是很难挑战谷歌，但是它有office这套软件系统，有windows操作系统，把这些能力跟自己原有的优势做结合。

比如说像谷歌，我可以跟安卓系统，可以跟搜索引擎做结合，这些方向上会更强势。

其实可能在这不同的生态位上，每个公司可能会有自己独特的优势。

比如说像苹果完全可以跟Siri结合，直接跟终端硬件绑定了。

特斯拉也一样，特斯拉跟OpenAI有这种投资人的关系，但是OpenAI肯定也是没有办法直接获取特斯拉在智能驾驶上的这些数据的，要么以把SDK或者API授权给特斯拉使用，要不特斯拉自己干了。

所以基本上是这样的。

    12、您刚才说在一些细分领域，比如政务、金融这些领域，这些可能是某种程度上属于GPT这套，大模型最容易去落地的，比较容易落地的几个场景。

如果从落地的难易度的角度，您觉得哪些领域会比较快？

    A：在落地领域，最快可能还是在工具软件上。

因为我们刚才提到了，类似ChatGPT这个技术有一个很容易被大家忽略的风险点，就是AIGC的过程。

当然我们在前几天，比如说新Bing的体验上已经可以看到，比如说它去分析GAP的行情是上涨，但是实际上是下跌的，其实问题恰恰出在这，这里面有信息的二次加工问题，尽管你提供了信息源，但是我们看它有足够的理性，有足够的分辨能力可以甄别这些信息。

但是对于绝大多数普通用户来说不具备这些分析能力，也没有这样的理性，也不愿意分辨。

这个时候出现问题直接承担责任的就是信息的提供方。

所以具体的交互形态上，我们可以得出这么一条结论。

    第一，不是所有的内容适合AIGC，就像我们谈到的金融科技、数字政务、教育、医疗，很多1就是1，2就是2，AIGC需要划定一个范围。

    第二，细节的算法需要做一些优化。

现在有的人在不管是调侃也好，或者别有用心也好，可以对ChatGPT回答的内容做诱导，这个也存在问题。

    当然，在具体的内容上多少存在偏意识形态或者这些方面的问题，这个可能会更加的危险。

所以大家可能在去用这个技术的时候，刚才说的由于内容的真实性和可靠性这块引发的一些小的问题，看起来很小的问题，需要先解决掉。

然后才是跟商业做深度应用的结合。

再把这种技术跟行业深度应用的时候，其实有一个最后一公里的问题需要解决，主要在多模态交互上，我们知道在ChatGPT，我们跟它交流的时候使用的输入文本的方式。

但是真正在高速上比如说开车，或者在银行网点办理业务，这些场景基本上用户跟这些智能机或者AI去交流的时候，基本上采用语音交互的方式为主，不可能说我还要去提供一个键盘输入文本，几乎不存在这样一种情况。

所以我们可能目前像阿里、百度，也包括微软这些公司提供的智能语音的这些产品，90%的识别准确率没办法满足线下对答如流，答非所问这种实际应用的要求，这些基本上可以理解为最后一公里的要求，得先把这些问题解决了，才能更多的跟行业应用做更深度的结合。

    13、除了刚才说的这种大的，像微软、谷歌本来就有大的软件，或者大量的流量入口，比如说像谷歌搜索，或者office，在一些垂直领域，类似于刚才说的金融、政务，小公司比大模型不用比了，完全不是一个量级。

最终这些垂直领域的公司，是不是大部分会演变成使用巨头的模型来做行业应用的应用型的公司？

    A：对，相当于巨头们更多做的基建的产品，他们提供基础的能力。

行业里面还是有初创团队，或者中小公司，他们做处理技术应用的这些问题。

而且技术应用这块对于大厂来说，他们觉得这些属于苦活，累活，也不愿意去干这些东西。

    但是这里面也存在一个巨大的机会，我们刚才已经提到了，多模态交互是一个非常复杂的，比如说我们在银行网点，开车的时候，它的环境，极度嘈杂，车内存在多个人。

这时候我们说话的话，AI需要自主的分辨出来跟谁说话，或者这些人说话是不是要听，要不要做出回应等等，它是非常复杂的东西。

这里面就像当初上世纪70-80年代的时候，微软和苹果抄袭施乐的界面，有了现在以键盘、鼠标、触控为代表的操作界面一样，谁在服务的过程中把交互的部分冲击出来，ChatGPT作为核心，实际上就是下一代的操作系统。

我们知道操作系统像谷歌、微软、苹果，三家公司的市值大概7万亿美金左右，这个想象力空间是足够的。

再有偏一些智能设备的助手方向的，比如说像苹果的Siri，小米的小爱同学等等，类似这些产品也会有这样的机会，比如把这种能力跟自己的语音助手做结合，未来一旦做好了，也不排除分拆独立的可能性，成长为更好的，更有价值的产品。

因为现在ChatGPT回答我们任何人的时候，你可以理解为它就是一个ChatGPT。

但是未来它完全可以更加的以个性化，比如说你聊的时候，它可能像成龙，我聊的时候可能像肖战，带有比较鲜明的人设特征的，可以满足用户的个性化方面的一些需求。

    14、从相对中长期来看，一方面有大模型的大厂，以及掌握大的流量入口的大厂，不管搜索引擎还是offic，具有丰富的用户群体直接受益了。

另外一块比如说掌握语音技术的，掌握跟人交流技术的，相当于把后面大模型更好的跟人机交流搭起桥梁的。

其他方面您觉得还有一些什么样的方向，或者说细分领域可能会受益于这个浪潮？

    A：这块其实主要看好五个大的方向。

    第一，做基础算法的。

就是OpenAI、百度文心，谷歌的Bard等等，有一堆算法的。

但是他们的商业模式相对比较简单，一种面向企业和开发者提供的标准的SDK和API。

再有我在这个基础上把它稍微功能化处理一下，变成有点像功能软件，比如说处理表格用来写小作文类似这种功能，以订阅的方式向终端用户提供。

但是这两种商业模式的附加值不够高，这是基础，而且研发成本又投入大，这是第一类方向可能会存在的一个困境。

    第二，提供基础算力和应用服务部署这方面的，主要是有这么三类公司，一类是像英伟达、寒武纪这种做基础芯片、显卡的公司。

第二类像华为云、阿里云、百度智能云这种提供云服务的公司。

第三类因为我们已经看到了GPT4要推出的时候会增强这种多向模态的能力，现在ChatGPT更多的处理文本，文本对算力的要求更少。

未来我要增强音视频、度片类似这方面的处理，会要求更高的算力，还会有一堆专门处理音视频处理，或者图片处理的，提供这些算力支持的公司，比如说有一些新型的，像平行云类似于这些，但是都提供基础的算力支撑，包括服务部署方面的公司。

    第三，刚才已经提到了，主要是技术应用。

比如说跟搜索引擎的结合，跟操作系统的结合，跟个人助手的结合，跟工具软件的结合，或者是我就是干脆直接的垂直行业的应用，比如说进入科技领域，比如说像海康威视，它有渠道和客户资源，我把原有的能力跟硬件产品做结合，它也能够在这里面获得足够的成长和机会。

相当于渠道和客户在这里面也会非常关键的。

    第四，刚才讲了软的东西，讲了算法，这些东西我要拿过来给终端的用户做交互的话，我都会依赖一个载体。

比如说智能手机，可能是一台智能汽车，也可能在未来甚至眼角膜植入芯片，可能满足用户交互的东西。

所以相当于在物联网终端这块，跟ChatGPT这种技术做结合，也是有很大的机会的。

第五，在AIGC这样一个方向上。

因为有了软件，有了硬件，用户跟软硬件结合在一起的智慧体系交互的时候，需要大量的内容。

单纯靠人工生产的效率太低了，所以使用AIGC的技术，生产比如说不管是文本、图片、音视频内容的提供方，在这个过程中也会有足够的机会。

    15、您的公司应该也是做类似于终端这块的是吧？

    A：我们在过去的几年时间里面，主要是给银行和政府提供服务，把刚才说的这些技术，比如说智能语音、NLP，甚至还有数字人的这些软硬件结合在一起，解决一些无接触产品和服务的东西，软硬件结合在一起的。

比如说以金融行业的银行业举例，有一个巨大的需求，我们知道传统的银行行业是人力资产密集型的，因为疫情的影响也好，或者现在技术进步的影响也好，现在中老年人可能不方便去，年轻人不爱去，这种柜台业务极度萎缩，所以银行面临着巨大的降本增效的压力。

要解决这个问题无非就是两条路径可以走。

    第一，对现有的银行网点进行升级改造，提升智能化、数字化的水平。

所以这里面可能会部署一套软件，外加上配套的，比如说一个网点部署5-10台左右的硬件。

原来一个网点要雇20个人，现在只要雇两个人就可以了，这是一个方向。

再有这个网点实在运营成本太高，需要把它裁撤掉，这个柜台业务尽管少还是要有，需要应对这种需求的变化。

那怎么办？

可能有点类似无人超市的产品，一台售价70-80万人民币，原来的网点可以覆盖20-30个小区，这种设备前置部署到小区，从总的成本投入上要员大于网点运营的，但是可以增加便捷性。

以前我要驾车或者乘坐公共交通工具去网点柜台办理业务，现在下楼可能就能办理了。

这种技术在ChatGPT的加持下有可能取得大的突破。

我们知道全国银行网点有22万个，这个规模是足够的。

    16、您说的软硬一体的表现形式是什么？

是类似于我们平时接触的ATM吗？

是一个机器还是什么？

它可能和我们平时接触的ATM机器有什么不一样？

能处理非现场业务还是什么？

具体的形式是什么样的？

A：比如说跟ATM这种机具结合在一起，也会有屏幕，就是当你在办理业务的时候，遇到问题的时候，会有一个数字人代表的AI，通过语音对话的方式直接跟用户交流，这样就不需要在大堂部署客户经理了，相当于这么一种做法。

这块从2019年末，2020年初就开始做这些事情了比如说在中行网点，在浙江省银行，在很多地方开始部署了。

    17、在政务领域呢？

能类似的举一个例子吗？

因为大家对应用场景没有一个感性的认知。

    A：在政务领域其实跟我们给银行提供服务是类似的，比如说党建，一个村党支部，或者我智慧社区，我一个社区的办公室，可能也是类似于银行网点部署，它也是软硬件结合在一起去做，只不过从收费模式上略有差距。

但是相比较提供基础的模型，它是一个高附加值的，因为软件就是按软件授权，硬件就是按照肯定会做足够的毛利空间，目前大概是40%左右。

软件因为不同的行业，其实它只是在内容差异，比如说我把银行的数据拿过来，我训练大概有6-12个小时，训练完了就可以部署了，同样一套软件，把这个东西拿过来，把政务的数据拿过来也是训练类似这么长的时间就可以处理了。

我是说单纯从交互层面上，在不同的行业差异只在一些不同的RPA流程，比如说在银行是办卡，跟柜台业务有关的东西，数字政务更多的是跟政策，跟民生服务相关的，智能流程自动化模块的接入会有差异化，会有一些不同的地方。

但是未来这个方向可以通过类似开放平台的方式去做处理。

   18、您现在用的是一套自己的模型和算法，数据是属于银行的，拿到他们的场景里用他们的数据训练，实现一个最终能够对话，或者能够解答问题的效果？

A：对。

    19、如果百度推出这个，或者国内基于中文体系推出这个的情况下，从您自己发展的规划来说，您准备自研一套呢，还是接入到大厂里面去？

A：单从我们自己来说，我们这个过程中一直和商汤、百度、阿里、腾讯这种级别的公司存在比较直接的竞争关系，所以我们在这个过程中肯定用自己的。

但是我们和他相比我们的优势在什么地方？

我们的优势可能不是在于基础模型的研发，我们在解决最后一公里的问题。

比如说一个智能机具，前面你和我，我们两个人都站在智能机具面前，它处于唤醒状态的时候，咱们两个人同时说话，这个时候它需要判断出来需要跟谁去交互，或者咱们俩说的话它是否需要做出回应，它必须得具备这种能力。

这种工作对于大厂来说，它没有下沉到这么深的地方去专门干这些事情，它也认为这些成本对于他们来说，或者收益对于他们来说，完全不成正本的，他们看不上这块的东西。

    20、背后的大模型，有些开源的技术可以去采用是吧？

站在巨人的肩膀上，不用从头研发的。

A：是这样的，但是你获得的数去有独特的优势。

比如说单纯的语音识别上来说，比如说迅飞做语音识别最好的，但是你把AFR这个功能放到网点上发现出错的几率太高了，所以还是需要专门针对这块做大量的纠错算法的处理，推理的一些处理，还需要做大量的训练。

这就是小的创业团队也好，或者专门做这块服务的企业也好，他可能在这块具有优势。

    21、一方面利用已有的开源的，或者框架性的东西，不用从最底层开始做，在某些方面可以深耕是吧？

A：是这样的。

    22、如果软硬一体的话整个毛利率做到40%以上。

如果是软件的话，相当于把软件加到现有的机具里面去，可能是更高毛利的收益的？

A：硬件大概是40%-45%，软件这块可以做到70%以上，大概这样的。

    23、其他的交付还需要什么？

除了硬件采购的成本之外，还有别的成本吗？

比如说现场安装配制这些。

    A：那些成本都包含在内。

（来自韭研公社APP）